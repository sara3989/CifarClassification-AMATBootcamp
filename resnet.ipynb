{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:21:19.345138Z","iopub.execute_input":"2023-08-02T13:21:19.345541Z","iopub.status.idle":"2023-08-02T13:21:19.455739Z","shell.execute_reply.started":"2023-08-02T13:21:19.345511Z","shell.execute_reply":"2023-08-02T13:21:19.454321Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import transforms\nfrom sklearn.model_selection import train_test_split\nimport logging\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:20:06.927847Z","iopub.execute_input":"2023-08-02T13:20:06.928222Z","iopub.status.idle":"2023-08-02T13:20:12.467167Z","shell.execute_reply.started":"2023-08-02T13:20:06.928191Z","shell.execute_reply":"2023-08-02T13:20:12.465964Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Preproccessing the Data**","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image = self.data[idx]\n        label = self.labels[idx]\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:51:31.101116Z","iopub.execute_input":"2023-08-02T12:51:31.101782Z","iopub.status.idle":"2023-08-02T12:51:31.111156Z","shell.execute_reply.started":"2023-08-02T12:51:31.101746Z","shell.execute_reply":"2023-08-02T12:51:31.110095Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def split_into_train_validation_test(df: pd.DataFrame, random_state: int, test_size: float):\n    # X - pixels of images\n    pixels = [col for col in df.columns if col.startswith('pixel')]\n    X = df[pixels]\n    y = np.array(df['label'])\n    \n    # Split into train & test\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=random_state)\n    # Split into train & validation\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = test_size, random_state=random_state)\n\n    return X_train, X_val, X_test, y_train, y_val, y_test","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:20:12.468933Z","iopub.execute_input":"2023-08-02T13:20:12.469729Z","iopub.status.idle":"2023-08-02T13:20:12.476334Z","shell.execute_reply.started":"2023-08-02T13:20:12.469688Z","shell.execute_reply":"2023-08-02T13:20:12.475399Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def data_preparation(data: pd.DataFrame, labels, device='cuda'):\n    # Reshape the data to match the image dimensions (3, 32, 32)\n    data = data.values.reshape(-1, 3, 32, 32)\n\n    # Convert data to float32 and normalize to the range [0, 1]\n    data = data.astype(np.float32) / 255.0\n\n    # Convert NumPy arrays to PyTorch tensors\n    data_tensors = torch.tensor(data).to(device)\n    label_tensors = torch.tensor(labels).to(device)\n    \n    # Standardize\n    normalize_transform = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[1.0, 1.0, 1.0])\n\n    # Create a CustomDataset instance\n    dataset = CustomDataset(data_tensors, label_tensors)\n\n    # Create a DataLoader\n    batch_size = 32\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    return loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_imbalance = pd.read_csv(\"/kaggle/input/cifar-10-and-3-classes-from-cifar-100-imbalance/dataset.csv\")\n# X_train_imbalance, X_val_imbalance, X_test_imbalance, y_train_imbalance, y_val_imbalance, y_test_imbalance = split_into_train_validation_test(df_imbalance, random_state = 42, test_size = 0.2)\n# train_loader_imbalance = data_preparation(X_train_imbalance, y_train_imbalance)\n# val_loader_imbalance = data_preparation(X_val_imbalance, y_val_imbalance)\n# test_loader_imbalance = data_preparation(X_test_imbalance, y_test_imbalance)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:30:40.295087Z","iopub.execute_input":"2023-08-02T12:30:40.295501Z","iopub.status.idle":"2023-08-02T12:30:40.306652Z","shell.execute_reply.started":"2023-08-02T12:30:40.295473Z","shell.execute_reply":"2023-08-02T12:30:40.305632Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/perfect-dataset/perfect_dataset.csv\")\nX_train, X_val, X_test, y_train, y_val, y_test = split_into_train_validation_test(df, random_state = 66, test_size = 0.2)\ntrain_loader = data_preparation(X_train, y_train)\nval_loader = data_preparation(X_val, y_val)\ntest_loader = data_preparation(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:30:40.308022Z","iopub.execute_input":"2023-08-02T12:30:40.308309Z","iopub.status.idle":"2023-08-02T12:31:33.449502Z","shell.execute_reply.started":"2023-08-02T12:30:40.308275Z","shell.execute_reply":"2023-08-02T12:31:33.448392Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Resnet18 model - Tensorboard","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\nimport os\nfrom tensorboardX import SummaryWriter\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:31:33.452741Z","iopub.execute_input":"2023-08-02T12:31:33.453131Z","iopub.status.idle":"2023-08-02T12:31:33.587724Z","shell.execute_reply.started":"2023-08-02T12:31:33.453092Z","shell.execute_reply":"2023-08-02T12:31:33.586744Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:31:33.589063Z","iopub.execute_input":"2023-08-02T12:31:33.590389Z","iopub.status.idle":"2023-08-02T12:31:33.597771Z","shell.execute_reply.started":"2023-08-02T12:31:33.590344Z","shell.execute_reply":"2023-08-02T12:31:33.596869Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# def append_dropout(model, rate=0.2):\n#     for name, module in model.named_children():\n#         if len(list(module.children())) > 0:\n#             append_dropout(module)\n#         if isinstance(module, nn.ReLU):\n#             new = nn.Sequential(module, nn.Dropout2d(p=rate, inplace=True))\n#             setattr(model, name, new)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T08:22:26.305669Z","iopub.execute_input":"2023-08-02T08:22:26.306639Z","iopub.status.idle":"2023-08-02T08:22:26.322467Z","shell.execute_reply.started":"2023-08-02T08:22:26.306601Z","shell.execute_reply":"2023-08-02T08:22:26.321256Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def compute_confusion_matrix(model, data_loader, labels_df: pd.DataFrame, num_classes:int, device = \"cuda\"):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Compute the confusion matrix\n    class_names = [df.loc[i + 1] for i in range(num_classes)]  # Replace 'num_classes' with the actual number of classes\n    conf_matrix = confusion_matrix(all_labels, all_preds)\n\n    return conf_matrix, class_names","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:31:33.599481Z","iopub.execute_input":"2023-08-02T12:31:33.599845Z","iopub.status.idle":"2023-08-02T12:31:33.612630Z","shell.execute_reply.started":"2023-08-02T12:31:33.599814Z","shell.execute_reply":"2023-08-02T12:31:33.611564Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def resnet18_model_with_tensorboard(num_epochs: int, train_loader, val_loader, num_classes: int, device='cuda'):\n    # Define the ResNet18 model\n    model = models.resnet18(pretrained=False).to(device)\n    model.fc = nn.Linear(512, num_classes).to(device)\n    \n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n\n    # Set up TensorBoard writer\n    writer = SummaryWriter('logs')\n    os.makedirs('/kaggle/working/MyResNet18Models')\n\n    num_train_batches = len(train_loader)\n    for epoch in range(num_epochs):\n        model.train()  # Set the model to training mode\n        train_loss = 0.0\n\n        for i, (images, labels) in enumerate(train_loader):\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        # Calculate average training loss for the epoch\n        train_loss /= num_train_batches\n        \n        model.eval()  # Set the model to evaluation mode\n        val_loss = 0.0\n        num_val_batches = len(val_loader)\n\n        with torch.no_grad():  \n            for batch_idx, (val_inputs, val_labels) in enumerate(val_loader):\n                val_outputs = model(val_inputs)\n                val_loss_batch = criterion(val_outputs, val_labels)\n                val_loss += val_loss_batch.item()\n\n        val_loss /= num_val_batches\n        \n        train_accuracy = evaluate_model(model, train_loader)\n        val_accuracy = evaluate_model(model, val_loader)\n\n        # Write to TensorBoard\n        writer.add_scalars('Loss', {'Train': train_loss, 'Validation': val_loss}, epoch)\n        writer.add_scalars('Accuracy', {'Train': train_accuracy, 'Validation': val_accuracy}, epoch)\n        \n#         if (epoch + 1) % 20 == 0 or epoch == num_epochs:\n        torch.save(model.state_dict(), f'/kaggle/working/MyResNet18Models/resnet18_model_{epoch + 1}.pth')\n        \n    # Close the TensorBoard writer\n    writer.close()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:31:33.614280Z","iopub.execute_input":"2023-08-02T12:31:33.614668Z","iopub.status.idle":"2023-08-02T12:31:33.627649Z","shell.execute_reply.started":"2023-08-02T12:31:33.614636Z","shell.execute_reply":"2023-08-02T12:31:33.626533Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree(\"/kaggle/working/MyResNet18Models\")\n# shutil.rmtree(\"/kaggle/working/logs\")\n# import os\n# os.remove(\"/kaggle/working/imbalnceData.zip\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:32:51.790406Z","iopub.execute_input":"2023-08-02T11:32:51.790793Z","iopub.status.idle":"2023-08-02T11:32:51.799727Z","shell.execute_reply.started":"2023-08-02T11:32:51.790761Z","shell.execute_reply":"2023-08-02T11:32:51.798818Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# imbalance_model = resnet18_model_with_tensorboard(30, train_loader_imbalance, val_loader_imbalance, 13)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imbalance_data_accuracy = evaluate_model(imbalance_model, val_loader_imbalance)\n# print(\"Test Accuracy: {:.2f}%\".format(imbalance_data_accuracy))","metadata":{"execution":{"iopub.status.busy":"2023-08-02T09:35:30.410186Z","iopub.execute_input":"2023-08-02T09:35:30.410552Z","iopub.status.idle":"2023-08-02T09:35:30.970985Z","shell.execute_reply.started":"2023-08-02T09:35:30.410523Z","shell.execute_reply":"2023-08-02T09:35:30.970014Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Test Accuracy: 40.81%\n","output_type":"stream"}]},{"cell_type":"code","source":"model = resnet18_model_with_tensorboard(30, train_loader, val_loader, 13)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:33:00.193771Z","iopub.execute_input":"2023-08-02T11:33:00.194137Z","iopub.status.idle":"2023-08-02T11:43:13.583921Z","shell.execute_reply.started":"2023-08-02T11:33:00.194108Z","shell.execute_reply":"2023-08-02T11:43:13.582834Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"accuracy = evaluate_model(model, val_loader)\nprint(\"Test Accuracy: {:.2f}%\".format(accuracy))","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:43:18.151596Z","iopub.execute_input":"2023-08-02T11:43:18.152658Z","iopub.status.idle":"2023-08-02T11:43:18.866435Z","shell.execute_reply.started":"2023-08-02T11:43:18.152622Z","shell.execute_reply":"2023-08-02T11:43:18.865428Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Test Accuracy: 37.60%\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\ndf_pixels = df[filter(lambda x: x.startswith('pixel') == True, df.columns)]\nfig, ax = plt.subplots(figsize=(1,1))\nax.imshow(np.array(df_pixels.iloc[random.choice(range(df_pixels.shape[0]))]).reshape(32,32,3))","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:36:13.198629Z","iopub.execute_input":"2023-08-02T12:36:13.199048Z","iopub.status.idle":"2023-08-02T12:36:14.041753Z","shell.execute_reply.started":"2023-08-02T12:36:13.199016Z","shell.execute_reply":"2023-08-02T12:36:14.040675Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7d4242b529b0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 100x100 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAHwAAAB9CAYAAABgQgcbAAAACXBIWXMAAAPoAAAD6AG1e1JrAAACs0lEQVR4nO3aMWrlMBSF4axcBAaDKy0j4EYbUDW4i3BltIvXZODVGrKHhHsffIVWIN///Fc+b/++vtYrnHZ8pD/n357+vEVfpAvvLtyEdxMejesG6ZDeZLgMPxOIGWmD9MXSDxkevnrZwzuke3jpMjx6/Wpe2iC9eVqV4WeCNcxb+gHp4QbO0rsJ93u0Q3q0hTeWDulNAUKGnwlsnKVD+lJxOmR42hMtZI20ufCm8WLCzwRiRtogfWm8HDI8XMxIW4d0lt5lePT61TReIL1pvMjwM8EapvFyQHq4gbP0bsK9pXdIj7bwxtIhvWm8yPAzgY2zdEhfGi+HDA9fvzReOqSrOHUZnvGcryBtj8djvcKp25/0Z38v6Y8L31x4+DSb8GLCo3FdId2EVxkO6XsCMSNtkL5Y+ibDw02cpRdI9/BSZHj0+lW9tEF69bQqw/cEa5i39A3Sww2cpRcT7vdogfRoC68sHdKrAoQM3xPYOEuH9KXitMnw8PVLxalA+vdHEG3glaWb8KriBOl7AhNn6ZC+VJw2GR5u4iy9QLqKU5Hh0etXVXGC9KriJMP3BGuYitMG6eEGztKLCVdxKpAebeGVpUN6VXGS4XsCG2fpkL5UnDYZHr5+qTgVSFdxKj+X4c/nc73Cmfed/lyfI/1x4bcLD59mEz5MeDSuJ6Sb8CnDIf1KIGakDdIXS79leLiJs/QB6R5ehgyPXr+mlzZIn55WZfiVYA3zln5DeriBs/Rhwv0eHZAebeGTpUP6VICQ4VcCG2fpkL5UnG4ZHr5+qTgNSP/+CKINfLJ0Ez5VnCD9SmDiLB3Sl4rTLcPDTZylD0hXcRoyPHr9mipOkD5VnGT4lWANU3G6IT3cwFn6MOEqTgPSoy18snRInypOMvxKYOMsHdKXitMtw8PXLxWn8atI/w+h34uhT8CS5QAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"code","source":"labels_df = pd.read_csv(\"/kaggle/input/labels-names/dataset_names.csv\")\nconf_matrix, class_names = compute_confusion_matrix(model_29, val_loader, labels_df, num_classes = 13)\nsns.heatmap(conf_matrix, annot = True, cmap = 'Blues', xticklabels = class_names, yticklabels = class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r imbalnceData.zip /kaggle/working/logs","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:43:47.750542Z","iopub.execute_input":"2023-08-02T11:43:47.751587Z","iopub.status.idle":"2023-08-02T11:43:49.021617Z","shell.execute_reply.started":"2023-08-02T11:43:47.751538Z","shell.execute_reply":"2023-08-02T11:43:49.020221Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/logs/ (stored 0%)\n  adding: kaggle/working/logs/Accuracy/ (stored 0%)\n  adding: kaggle/working/logs/Accuracy/Validation/ (stored 0%)\n  adding: kaggle/working/logs/Accuracy/Validation/events.out.tfevents.1690976001.b031da16716c (deflated 56%)\n  adding: kaggle/working/logs/Accuracy/Train/ (stored 0%)\n  adding: kaggle/working/logs/Accuracy/Train/events.out.tfevents.1690976001.b031da16716c (deflated 56%)\n  adding: kaggle/working/logs/events.out.tfevents.1690975980.b031da16716c (deflated 5%)\n  adding: kaggle/working/logs/Loss/ (stored 0%)\n  adding: kaggle/working/logs/Loss/Validation/ (stored 0%)\n  adding: kaggle/working/logs/Loss/Validation/events.out.tfevents.1690976001.b031da16716c (deflated 52%)\n  adding: kaggle/working/logs/Loss/Train/ (stored 0%)\n  adding: kaggle/working/logs/Loss/Train/events.out.tfevents.1690976001.b031da16716c (deflated 52%)\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_model(model_path, device='cuda'):\n    model = models.resnet18(pretrained=False)\n    model.fc = nn.Linear(512, 13)\n    model.load_state_dict(torch.load(model_path))\n    model.to(device)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:30:36.856476Z","iopub.execute_input":"2023-08-02T11:30:36.857541Z","iopub.status.idle":"2023-08-02T11:30:36.864698Z","shell.execute_reply.started":"2023-08-02T11:30:36.857500Z","shell.execute_reply":"2023-08-02T11:30:36.863851Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model_29 = load_model(\"/kaggle/input/models-imbalance-data/resnet18_model_29.pth\")#\"/kaggle/input/models-imbalance-data/resnet18_model_29.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:30:38.042872Z","iopub.execute_input":"2023-08-02T11:30:38.043230Z","iopub.status.idle":"2023-08-02T11:30:38.735461Z","shell.execute_reply.started":"2023-08-02T11:30:38.043200Z","shell.execute_reply":"2023-08-02T11:30:38.734369Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate_model(model_29, val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = load_model(model, '/kaggle/working/MyResNet18Models/resnet18_model_29.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir logs --host localhost --port 8088","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\n\nmodel = models.resnet18()\n\ndef append_dropout(model, rate=0.2):\n    for name, module in model.named_children():\n        if len(list(module.children())) > 0:\n            append_dropout(module)\n        if isinstance(module, nn.ReLU):\n            new = nn.Sequential(module, nn.Dropout2d(p=rate, inplace=True))\n            setattr(model, name, new)\n\n\nappend_dropout(model)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:21:19.457499Z","iopub.execute_input":"2023-08-02T13:21:19.458132Z","iopub.status.idle":"2023-08-02T13:21:19.687725Z","shell.execute_reply.started":"2023-08-02T13:21:19.458096Z","shell.execute_reply":"2023-08-02T13:21:19.686765Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): Sequential(\n    (0): ReLU(inplace=True)\n    (1): Dropout2d(p=0.2, inplace=True)\n  )\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): Sequential(\n        (0): ReLU(inplace=True)\n        (1): Dropout2d(p=0.2, inplace=True)\n      )\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): Sequential(\n        (0): ReLU(inplace=True)\n        (1): Dropout2d(p=0.2, inplace=True)\n      )\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): Sequential(\n        (0): ReLU(inplace=True)\n        (1): Dropout2d(p=0.2, inplace=True)\n      )\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): Sequential(\n        (0): ReLU(inplace=True)\n        (1): Dropout2d(p=0.2, inplace=True)\n      )\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): Sequential(\n        (0): ReLU(inplace=True)\n        (1): Dropout2d(p=0.2, inplace=True)\n      )\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): Sequential(\n        (0): ReLU(inplace=True)\n        (1): Dropout2d(p=0.2, inplace=True)\n      )\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): Sequential(\n        (0): ReLU(inplace=True)\n        (1): Dropout2d(p=0.2, inplace=True)\n      )\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): Sequential(\n        (0): ReLU(inplace=True)\n        (1): Dropout2d(p=0.2, inplace=True)\n      )\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/perfect-dataset/perfect_dataset.csv\")\nX_train, X_val, X_test, y_train, y_val, y_test = split_into_train_validation_test(df, random_state = 66, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:20:28.914427Z","iopub.execute_input":"2023-08-02T13:20:28.914790Z","iopub.status.idle":"2023-08-02T13:21:19.343321Z","shell.execute_reply.started":"2023-08-02T13:20:28.914760Z","shell.execute_reply":"2023-08-02T13:21:19.342273Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnp.random.seed(123) # for reproducibility\n\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, MaxPool2D, Conv2D, Dense, Reshape, Dropout\nfrom keras.utils import np_utils\n\nX_train_tf = X_train.values.reshape(X_train.shape[0], 32, 32, 3)\nX_val_tf = X_val.values.reshape(X_val.shape[0], 32, 32, 3)\nX_test_tf = X_test.values.reshape(X_test.shape[0], 32, 32, 3)\nX_train_tf = X_train_tf.astype('float32')\nX_val_tf = X_val_tf.astype('float32')\nX_test_tf = X_test_tf.astype('float32')\nX_train_tf /= 255\nX_val_tf /= 255\nX_test_tf /= 255\nY_train_tf = np_utils.to_categorical(y_train, 13)\nY_val_tf = np_utils.to_categorical(y_val, 13)\nY_test_tf = np_utils.to_categorical(y_test, 13)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:21:22.779981Z","iopub.execute_input":"2023-08-02T13:21:22.781178Z","iopub.status.idle":"2023-08-02T13:21:31.612889Z","shell.execute_reply.started":"2023-08-02T13:21:22.781135Z","shell.execute_reply":"2023-08-02T13:21:31.611713Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 32\nnum_classes = 13\nepochs = 50\ninput_shape = (32, 32, 3)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:21:39.676461Z","iopub.execute_input":"2023-08-02T13:21:39.677223Z","iopub.status.idle":"2023-08-02T13:21:39.682771Z","shell.execute_reply.started":"2023-08-02T13:21:39.677186Z","shell.execute_reply":"2023-08-02T13:21:39.681466Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"self.model = Sequential()\nself.model.add(Conv2D(64, (3, 3), padding='same',input_shape=input_shape))  # 32*32*64\nself.model.add(Activation('relu'))  # 32*32*64\nself.model.add(BatchNormalization())  # 32*32*64\nself.model.add(Conv2D(64, (3, 3)))  # 32*32*1 ->  30*30*64\nself.model.add(Activation('relu'))  # 30*30*64\nself.model.add(BatchNormalization())  # 30*30*64\nself.model.add(MaxPooling2D(pool_size=(2, 2)))  # 15*15*64\nself.model.add(Dropout(0.25))  # 15*15*64\nself.model.add(Conv2D(128, (3, 3), padding='same'))   # 15*15*1 -> 15*15*128\nself.model.add(Activation('relu'))  # 15*15*128\nself.model.add(BatchNormalization())  # 15*15*128\nself.model.add(Conv2D(128, (3, 3)))  # 15*15*1 -> 13*13*128\nself.model.add(Activation('relu'))  # 13*13*128\nself.model.add(BatchNormalization())  # 13*13*128\nself.model.add(MaxPooling2D(pool_size=(2, 2)))  # 6*6*128\nself.model.add(Dropout(0.25))  # 6*6*128\nself.model.add(Flatten())  # 4,608*1*1\nself.model.add(Dense(512, kernel_regularizer=l2(0.001)))  # 512*1*1\nself.model.add(Activation('relu'))  # 512*1*1\nself.model.add(Dropout(0.5))  # 512*1*1\nself.model.add(Dense(13))  # 10*1*1\nself.model.add(Activation('softmax')) # 10*1*1","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:21:41.438697Z","iopub.execute_input":"2023-08-02T13:21:41.439080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:06:57.680447Z","iopub.execute_input":"2023-08-02T13:06:57.680990Z","iopub.status.idle":"2023-08-02T13:06:57.696941Z","shell.execute_reply.started":"2023-08-02T13:06:57.680943Z","shell.execute_reply":"2023-08-02T13:06:57.695611Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(X_train_tf, Y_train_tf, batch_size = 32, validation_data = (X_val_tf, Y_val_tf) ,epochs = 50, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:09:49.317716Z","iopub.execute_input":"2023-08-02T13:09:49.319137Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1560/1560 [==============================] - 11s 6ms/step - loss: 1.9168 - accuracy: 0.3435 - val_loss: 1.8519 - val_accuracy: 0.3746\nEpoch 2/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.9051 - accuracy: 0.3460 - val_loss: 1.8442 - val_accuracy: 0.3760\nEpoch 3/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8993 - accuracy: 0.3503 - val_loss: 1.8474 - val_accuracy: 0.3758\nEpoch 4/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8982 - accuracy: 0.3502 - val_loss: 1.8441 - val_accuracy: 0.3719\nEpoch 5/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8946 - accuracy: 0.3509 - val_loss: 1.8395 - val_accuracy: 0.3752\nEpoch 6/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8873 - accuracy: 0.3531 - val_loss: 1.8196 - val_accuracy: 0.3827\nEpoch 7/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8843 - accuracy: 0.3544 - val_loss: 1.8396 - val_accuracy: 0.3788\nEpoch 8/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8822 - accuracy: 0.3555 - val_loss: 1.8186 - val_accuracy: 0.3849\nEpoch 9/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8783 - accuracy: 0.3581 - val_loss: 1.8150 - val_accuracy: 0.3825\nEpoch 10/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8739 - accuracy: 0.3588 - val_loss: 1.8171 - val_accuracy: 0.3833\nEpoch 11/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8724 - accuracy: 0.3609 - val_loss: 1.8241 - val_accuracy: 0.3763\nEpoch 12/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8710 - accuracy: 0.3578 - val_loss: 1.8175 - val_accuracy: 0.3928\nEpoch 13/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8601 - accuracy: 0.3648 - val_loss: 1.8419 - val_accuracy: 0.3707\nEpoch 14/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8656 - accuracy: 0.3620 - val_loss: 1.8023 - val_accuracy: 0.3896\nEpoch 15/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8661 - accuracy: 0.3611 - val_loss: 1.8143 - val_accuracy: 0.3894\nEpoch 16/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8629 - accuracy: 0.3642 - val_loss: 1.8101 - val_accuracy: 0.3879\nEpoch 17/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8640 - accuracy: 0.3634 - val_loss: 1.8146 - val_accuracy: 0.3913\nEpoch 18/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8595 - accuracy: 0.3637 - val_loss: 1.8158 - val_accuracy: 0.3892\nEpoch 19/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8557 - accuracy: 0.3653 - val_loss: 1.7975 - val_accuracy: 0.3948\nEpoch 20/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8517 - accuracy: 0.3682 - val_loss: 1.7965 - val_accuracy: 0.3911\nEpoch 21/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8501 - accuracy: 0.3671 - val_loss: 1.8065 - val_accuracy: 0.3885\nEpoch 22/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8461 - accuracy: 0.3661 - val_loss: 1.7961 - val_accuracy: 0.3940\nEpoch 23/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8443 - accuracy: 0.3709 - val_loss: 1.8079 - val_accuracy: 0.3940\nEpoch 24/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8468 - accuracy: 0.3687 - val_loss: 1.8060 - val_accuracy: 0.3882\nEpoch 25/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8450 - accuracy: 0.3676 - val_loss: 1.8056 - val_accuracy: 0.3918\nEpoch 26/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8438 - accuracy: 0.3697 - val_loss: 1.7993 - val_accuracy: 0.3965\nEpoch 27/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8385 - accuracy: 0.3711 - val_loss: 1.7933 - val_accuracy: 0.3972\nEpoch 28/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8367 - accuracy: 0.3716 - val_loss: 1.7925 - val_accuracy: 0.4023\nEpoch 29/30\n1560/1560 [==============================] - 9s 6ms/step - loss: 1.8361 - accuracy: 0.3722 - val_loss: 1.7958 - val_accuracy: 0.3972\nEpoch 30/30\n1560/1560 [==============================] - 10s 6ms/step - loss: 1.8359 - accuracy: 0.3730 - val_loss: 1.7926 - val_accuracy: 0.3986\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}